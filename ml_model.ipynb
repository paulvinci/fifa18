{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KNeighborsClassifier from sklearn.neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "# Create arrays for the features and the response variable\n",
    "y = df['party']\n",
    "X = df.drop('party',axis=1)\n",
    "\n",
    "# Create a k-NN classifier with 6 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Predict the labels for the training data X\n",
    "y_pred = knn.predict(X)\n",
    "\n",
    "# Predict and print the label for the new data point X_new\n",
    "new_prediction = knn.predict(X_new)\n",
    "print(\"Prediction: {}\".format(new_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the digits dataset: digits\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Print the keys and DESCR of the dataset\n",
    "print(digits.keys())\n",
    "print(digits.DESCR)\n",
    "\n",
    "# Print the shape of the images and data keys\n",
    "print(digits.images.shape)\n",
    "print(digits.data.shape)\n",
    "\n",
    "# Display digit 1010\n",
    "plt.imshow(digits.images[1010], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create feature and target arrays\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create a k-NN classifier with 7 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N_NEIGHBORS DETERMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop over different values of k\n",
    "for i, k in enumerate(neighbors):\n",
    "    # Setup a k-NN Classifier with k neighbors: knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)\n",
    "\n",
    "# Generate plot\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Testing model accuracy\n",
    "    ## Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "    ## Create a k-NN classifier with 7 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    ## Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "    ## Print the accuracy\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Defining data (df), target (y), features (X)\n",
    "df = \n",
    "X = \n",
    "Y =\n",
    "n_neighbors = \n",
    "\n",
    "# Defining optimal neighbors number\n",
    "    ## Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "    ## Loop over different values of k\n",
    "for i, k in enumerate(neighbors):\n",
    "    ## Setup a k-NN Classifier with k neighbors: knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    ## Fit the classifier to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    ## Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "    ## Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)\n",
    "\n",
    "    ## Generate plot\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Predict and print the label for the new data points (X_new)\n",
    "X_new\n",
    "new_prediction = knn.predict(X_new)\n",
    "print(\"Prediction: {}\".format(new_prediction))\n",
    "print(\"Accuracy :\"+int(knn.score(X_new, new_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL ACCURACY\n",
    "cannot do classic accuracy due to class imbalance issues\n",
    "so confusion matrix\n",
    "**accuracy** = (true pos & neg)/(true & false pos & neg)\n",
    "**precision** = true pos/(true & false pos)\n",
    "**recall/sensitivity/hit rate** = true pos / (true pos & false neg)\n",
    "**F1 score** = 2\\*(precision\\*recall)/(precision + recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42, stratify=y)\n",
    "\n",
    "# Instantiate a k-NN classifier: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression and the ROC curve\n",
    "despite its name it is used for classifier, for binary classification, outputting a probability p (above 0.5 to 1 - under to 0)\n",
    "ROC (Receiver Operating Curve) = true pos vs false pos curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LOGISTIC REGRESSION\n",
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ROC CURVE\n",
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reg one feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame: df\n",
    "df = pd.read_csv('gapminder.csv')\n",
    "\n",
    "# Create arrays for features and target variable\n",
    "y = df.life.values\n",
    "X = df.fertility.values\n",
    "\n",
    "# Print the dimensions of X and y before reshaping\n",
    "print(\"Dimensions of y before reshaping: {}\".format(y.shape))\n",
    "print(\"Dimensions of X before reshaping: {}\".format(X.shape))\n",
    "\n",
    "# Reshape X and y\n",
    "y = y.reshape(-1, 1)\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "# Print the dimensions of X and y after reshaping\n",
    "print(\"Dimensions of y after reshaping: {}\".format(y.shape))\n",
    "print(\"Dimensions of X after reshaping: {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Reg heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), square=True, cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the regressor: reg\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Create the prediction space\n",
    "prediction_space = np.linspace(min(X_fertility), max(X_fertility)).reshape(-1,1)\n",
    "\n",
    "# Fit the model to the data\n",
    "reg.fit(X_fertility, y)\n",
    "\n",
    "# Compute predictions over the prediction space: y_pred\n",
    "y_pred = reg.predict(prediction_space)\n",
    "\n",
    "# Print R^2 \n",
    "print(reg.score(X_fertility, y))\n",
    "\n",
    "# Plot regression line\n",
    "plt.plot(prediction_space, y_pred, color='black', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Create the regressor: reg_all\n",
    "reg_all = LinearRegression()\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "reg_all.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = reg_all.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2: {}\".format(reg_all.score(X_test, y_test)))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a linear regression object: reg\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Compute 5-fold cross-validation scores: cv_scores\n",
    "cv_scores = cross_val_score(reg, X, y, cv=5)\n",
    "\n",
    "# Print the 5-fold cross-validation scores\n",
    "print(cv_scores)\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized regression\n",
    "to deal with large coefficient, outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge regression**\n",
    "Loss function = OSL classic function + coef alpha \\* Sum(a \\** 2) alpha controls model complexity\n",
    "Chosing alpha is like chosing k in neighbors, it is hyperparamater tuning\n",
    "alpha = 0 (classic OLS, risk of overfitting), large alpha (risk of underfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(cv_scores, cv_scores_std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(alpha_space, cv_scores)\n",
    "\n",
    "    std_error = cv_scores_std / np.sqrt(10)\n",
    "\n",
    "    ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n",
    "    ax.set_ylabel('CV Score +/- Std Error')\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n",
    "    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n",
    "    ax.set_xscale('log')\n",
    "    plt.show()\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Setup the array of alphas and lists to store scores\n",
    "alpha_space = np.logspace(-4, 0, 50)\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []\n",
    "\n",
    "# Create a ridge regressor: ridge\n",
    "ridge = Ridge(normalize=True)\n",
    "\n",
    "# Compute scores over range of alphas\n",
    "for alpha in alpha_space:\n",
    "\n",
    "    # Specify the alpha value to use: ridge.alpha\n",
    "    ridge.alpha = alpha\n",
    "    \n",
    "    # Perform 10-fold CV: ridge_cv_scores\n",
    "    ridge_cv_scores = cross_val_score(ridge, X, y, cv = 10)\n",
    "    \n",
    "    # Append the mean of ridge_cv_scores to ridge_scores\n",
    "    ridge_scores.append(np.mean(ridge_cv_scores))\n",
    "    \n",
    "    # Append the std of ridge_cv_scores to ridge_scores_std\n",
    "    ridge_scores_std.append(np.std(ridge_cv_scores))\n",
    "\n",
    "# Display the plot\n",
    "display_plot(ridge_scores, ridge_scores_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso regression**\n",
    "Loss function = OSL classic function + coef alpha * abs(a)\n",
    "can be used to slecet import features, less important ones have coef shrink to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Instantiate a lasso regressor: lasso\n",
    "lasso = Lasso(alpha=0.4, normalize=True)\n",
    "\n",
    "# Fit the regressor to the data\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Compute and print the coefficients\n",
    "lasso_coef = lasso.coef_\n",
    "print(lasso_coef)\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.plot(range(len(df_columns)), lasso_coef)\n",
    "plt.xticks(range(len(df_columns)), df_columns.values, rotation=60)\n",
    "plt.margins(0.02)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
